{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This example shows how to use hyperopt to pick parameters for a MLP classifier on the MNIST handwritten digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "mnist = fetch_openml('mnist_784')\n",
    "\n",
    "# Scale the images to be between 0 and 1\n",
    "X = mnist.data / 255.\n",
    "y = mnist.target\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define an objective function to minimize\n",
    "# The classifier will be created, trained, and scored within this function\n",
    "def objective(args):\n",
    "    \n",
    "    # Build a classifier based on the parameters chosen\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(int(args['layer_size']),),\n",
    "                        max_iter=10,\n",
    "                        alpha=args['alpha'],\n",
    "                        solver=args['algorithm'],\n",
    "                        tol=1e-4, \n",
    "                        random_state=1,\n",
    "                        activation=args['activation'], \n",
    "                        learning_rate_init=args['learning_rate']\n",
    "                       )\n",
    "    \n",
    "    # Fit the classifier to the training data\n",
    "    mlp.fit(X_train, y_train)\n",
    "    \n",
    "    #NOTE: Normally you should use a separate 'validation' set here\n",
    "    #      and have a 'test' set that is only used on the final classifier\n",
    "    #      once parameters have been selected, the final classifier can be\n",
    "    #      retrained on both the 'training' and 'validation' sets\n",
    "    loss = -mlp.score(X_test, y_test)\n",
    "    \n",
    "    # Must return loss and status, any additional information can also be saved here.\n",
    "    # In this example the fully trained model is also returned\n",
    "    return {'loss': loss, 'status': STATUS_OK, 'model':mlp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the parameter space to search over\n",
    "# In this case the objective function is expecting a single dictionary argument, \n",
    "# so the space variable is set up to match that\n",
    "space = {'layer_size':hp.quniform('layer_size', 25, 100, 1),\n",
    "         'alpha':hp.lognormal('alpha', mu=np.log(1e-4), sigma=1),\n",
    "         'algorithm':hp.choice('algorithm', ['lbfgs', 'sgd', 'adam']),\n",
    "         'activation':hp.choice('activation', ['logistic', 'tanh', 'relu']),\n",
    "         #'learning_rate':hp.uniform('learning_rate', low=0.001, high=0.999),\n",
    "         'learning_rate':hp.loguniform('learning_rate', low=np.log(1e-4), high=np.log(1.)),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:43<00:00, 10.34s/trial, best loss: -0.9775]\n"
     ]
    }
   ],
   "source": [
    "# Create a Trials object to store results of each evaluation\n",
    "trials = Trials()\n",
    "\n",
    "# Run the search for the specified number of evaluations\n",
    "best = fmin(objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            trials=trials,\n",
    "            max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.994367\n",
      "Testing Accuracy: 0.977500\n"
     ]
    }
   ],
   "source": [
    "# Get the trained model from the best trial\n",
    "best_model = trials.best_trial['result']['model']\n",
    "\n",
    "# Compute the training and testing scores on this model\n",
    "print(\"Training Accuracy: %f\" % best_model.score(X_train, y_train))\n",
    "print(\"Testing Accuracy: %f\" % best_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 0,\n",
       " 'algorithm': 1,\n",
       " 'alpha': 0.0002548917899569714,\n",
       " 'layer_size': 78.0,\n",
       " 'learning_rate': 0.4305299897724264}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 2,\n",
       " 'tid': 5,\n",
       " 'spec': None,\n",
       " 'result': {'loss': -0.9775,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='logistic', alpha=0.0002548917899569714,\n",
       "                hidden_layer_sizes=(78,), learning_rate_init=0.4305299897724264,\n",
       "                max_iter=10, random_state=1, solver='sgd')},\n",
       " 'misc': {'tid': 5,\n",
       "  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'workdir': None,\n",
       "  'idxs': {'activation': [5],\n",
       "   'algorithm': [5],\n",
       "   'alpha': [5],\n",
       "   'layer_size': [5],\n",
       "   'learning_rate': [5]},\n",
       "  'vals': {'activation': [0],\n",
       "   'algorithm': [1],\n",
       "   'alpha': [0.0002548917899569714],\n",
       "   'layer_size': [78.0],\n",
       "   'learning_rate': [0.4305299897724264]}},\n",
       " 'exp_key': None,\n",
       " 'owner': None,\n",
       " 'version': 0,\n",
       " 'book_time': datetime.datetime(2024, 5, 5, 19, 10, 42, 303000),\n",
       " 'refresh_time': datetime.datetime(2024, 5, 5, 19, 10, 57, 224000)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': -0.8106,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='logistic', alpha=0.0001064369228523456,\n",
       "                hidden_layer_sizes=(95,), learning_rate_init=0.23091432935502323,\n",
       "                max_iter=10, random_state=1, solver='lbfgs')},\n",
       " {'loss': -0.8214,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='logistic', alpha=0.0002676406583180447,\n",
       "                hidden_layer_sizes=(94,),\n",
       "                learning_rate_init=0.00032816177283780275, max_iter=10,\n",
       "                random_state=1, solver='lbfgs')},\n",
       " {'loss': -0.944,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='tanh', alpha=0.00011136893118170627,\n",
       "                hidden_layer_sizes=(95,), learning_rate_init=0.6230101111806607,\n",
       "                max_iter=10, random_state=1, solver='sgd')},\n",
       " {'loss': -0.9724,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(alpha=0.0001726424609834143, hidden_layer_sizes=(84,),\n",
       "                learning_rate_init=0.28559769015889097, max_iter=10,\n",
       "                random_state=1, solver='sgd')},\n",
       " {'loss': -0.8871,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='tanh', alpha=5.9406786248453165e-05,\n",
       "                hidden_layer_sizes=(75,), learning_rate_init=0.00147891989356464,\n",
       "                max_iter=10, random_state=1, solver='lbfgs')},\n",
       " {'loss': -0.9775,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='logistic', alpha=0.0002548917899569714,\n",
       "                hidden_layer_sizes=(78,), learning_rate_init=0.4305299897724264,\n",
       "                max_iter=10, random_state=1, solver='sgd')},\n",
       " {'loss': -0.9147,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='tanh', alpha=0.00024386190667773452,\n",
       "                hidden_layer_sizes=(49,), learning_rate_init=0.09877888228104119,\n",
       "                max_iter=10, random_state=1)},\n",
       " {'loss': -0.9717,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(alpha=0.0010077388531178227, hidden_layer_sizes=(82,),\n",
       "                learning_rate_init=0.023826003621944737, max_iter=10,\n",
       "                random_state=1, solver='sgd')},\n",
       " {'loss': -0.9533,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='tanh', alpha=0.0011219728616999854,\n",
       "                hidden_layer_sizes=(37,), learning_rate_init=0.000617675712501093,\n",
       "                max_iter=10, random_state=1)},\n",
       " {'loss': -0.8928,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='tanh', alpha=0.00013742158613182166,\n",
       "                hidden_layer_sizes=(65,), learning_rate_init=0.09258627913041918,\n",
       "                max_iter=10, random_state=1, solver='lbfgs')}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
